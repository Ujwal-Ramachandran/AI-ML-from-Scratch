{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edde21c-1a2f-4ce8-8f89-f547b01f3272",
   "metadata": {},
   "source": [
    "# **Vector Databases & RAG**. \n",
    "\n",
    "Today, we focus on the \"Storage\" layer of the RAG (Retrieval-Augmented Generation) pipeline. You cannot feed a 500-page PDF into an LLM context window efficiently. Instead, we must break it down, convert it into mathematical representations (vectors), and store it in a database optimized for similarity search, not exact keyword matching.\n",
    "\n",
    "Here is the roadmap to build your local Knowledge Base ingestion engine.\n",
    "\n",
    "### Phase 1: Topic Breakdown\n",
    "\n",
    "```text\n",
    "L18: Vector Databases & Ingestion\n",
    "├── Concept 1: Vector Database Architecture (ChromaDB)\n",
    "│   ├── Dense Vectors vs. Sparse Vectors\n",
    "│   ├── Indexing (HNSW) vs. Exact Search\n",
    "│   ├── Intuition: High-dimensional space navigation\n",
    "│   ├── Simpler Terms: A library organized by \"meaning\" rather than \"alphabet\"\n",
    "│   └── Task: Initialize a persistent ChromaDB client\n",
    "│\n",
    "├── Concept 2: Document Loading (PDF Parsing)\n",
    "│   ├── Unstructured Data Extraction\n",
    "│   ├── Intuition: Turning binary PDF format into raw string data\n",
    "│   └── Task: Extract raw text from a PDF file using a library (e.g., pypdf)\n",
    "│\n",
    "├── Concept 3: Text Splitting (RecursiveCharacterTextSplitter)\n",
    "│   ├── Context Window Constraints\n",
    "│   ├── Semantic boundary preservation\n",
    "│   ├── Chunk Overlap intuition\n",
    "│   └── Task: Implement the splitting logic with overlap\n",
    "│\n",
    "├── Concept 4: Embedding Generation (The Bridge)\n",
    "│   ├── The role of the Embedding Model (e.g., OpenAI, HuggingFace)\n",
    "│   ├── Input (Text) -> Output (List of Floats)\n",
    "│   └── Task: Generate dummy or real embeddings for a text sample\n",
    "│\n",
    "├── Concept 5: Ingestion (Collections & Upsert)\n",
    "│   ├── Collections (Tables equivalent)\n",
    "│   ├── IDs, Embeddings, Documents, and Metadata association\n",
    "│   └── Task: Insert chunks into the ChromaDB collection\n",
    "│\n",
    "├── Concept 6: Metadata Filtering\n",
    "│   ├── Pre-filtering vs. Post-filtering\n",
    "│   ├── Hybrid search basics\n",
    "│   └── Task: Query the DB with a specific metadata constraint\n",
    "│\n",
    "└── Mini-Project: PDF Knowledge Base Builder\n",
    "    └── Build a script that takes a PDF path, processes it, and makes it searchable.\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85b4c7-dba0-47d3-9aba-9a22e06b3222",
   "metadata": {},
   "source": [
    "## Concept 1: Vector Database Architecture (ChromaDB)\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Traditional relational databases (SQL) are designed for precision. If you query `SELECT * FROM items WHERE color = 'red'`, the database checks for an exact string match. It either is \"red\" or it isn't.\n",
    "\n",
    "However, language is messy. \"Crimson\", \"Ruby\", and \"Scarlet\" are all semantically similar to \"Red\", but an SQL query would miss them. Vector Databases are designed to solve this. Instead of storing data as just text or numbers, they store data as **Vectors** (long lists of floating-point numbers) in a multi-dimensional space.\n",
    "\n",
    "In this space, concepts with similar meanings are located physically close to each other. Searching involves finding the \"Nearest Neighbors\" to a query vector, rather than exact row matching.\n",
    "\n",
    "### Mechanics: HNSW\n",
    "\n",
    "If you have 1 million vectors, calculating the distance between your query and every single vector (linear scan) is too slow for production.\n",
    "ChromaDB (and others like Weaviate/Pinecone) use **Approximate Nearest Neighbor (ANN)** algorithms. The most common is **HNSW (Hierarchical Navigable Small World)**.\n",
    "   * **Structure:** It builds a multi-layer graph. Top layers act like express highways (long jumps across the data), while bottom layers allow for fine-grained navigation.\n",
    "   * **Process:** The search starts at the top, zooms in on the general neighborhood, and descends until it finds the closest points in the bottom layer.\n",
    "\n",
    "### Simpler Explanation\n",
    "\n",
    "Imagine a massive library organized by \"Vibes\" instead of the Dewey Decimal System.\n",
    "   * **SQL** is like looking up a book by its exact ISBN number. You either find it or you don't.\n",
    "   * **Vector Search** is like saying, \"I want a book that feels like 'Harry Potter'\". The librarian (the Algorithm) walks to the Fantasy section (express jump), then looks at the shelf next to Rowling (local search) and hands you \"Percy Jackson\". It’s not the exact same book, but it's the closest match in meaning.\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "* **Pros:** Enables semantic search (searching by meaning, not keywords).\n",
    "* **Cons:** It is **Approximate**. There is a small chance the algorithm misses the absolute \"closest\" vector in favor of speed. It is also computationally heavier than simple keyword lookups.\n",
    "\n",
    "### Context\n",
    "\n",
    "In RAG (Retrieval-Augmented Generation), we use the Vector DB to find the 3-5 paragraphs from a PDF that are most relevant to the user's question, then send only those paragraphs to the LLM.\n",
    "\n",
    "---\n",
    "\n",
    "### Your Task\n",
    "\n",
    "You need to set up the infrastructure for our local knowledge base.\n",
    "\n",
    "**Requirements:**\n",
    "   1. Import the `chromadb` library.\n",
    "   2. Create a class named `VectorStore`.\n",
    "   3. In the `__init__` method, initialize a **Persistent Client**. This ensures that if you restart the script, the data isn't lost.\n",
    "      * *Hint:* You need to specify a path where the data will be saved.\n",
    "   4. Create (or get) a **Collection** named `my_knowledge_base`. A Collection is roughly equivalent to a Table in SQL.\n",
    "   \n",
    "   **Inputs:** None (Hardcoded path for now is fine, e.g., `./chroma_db`)\n",
    "   \n",
    "   **Outputs:** Print the collection object or its name to confirm creation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225224b7-cd62-4409-a568-4e38b126e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pypdf\n",
    "\n",
    "class VectorStore():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor contains path to the chroma db\n",
    "        \"\"\"\n",
    "        self.client = chromadb.PersistentClient(path = r\"Data/\")\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        \"\"\"\n",
    "        Create a new collection or gets the existing collection\n",
    "        \"\"\"\n",
    "        collection = self.client.get_or_create_collection(name = \"my_knowledge_base\")\n",
    "        return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9986ce-b224-4d2e-a66c-ffdf0deef892",
   "metadata": {},
   "source": [
    "This setup ensures your data survives between runs, which is critical for the \"Build Once, Query Many\" pattern of RAG applications.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Concept 2: Document Loading (PDF Parsing)**\n",
    "\n",
    "### Intuition\n",
    "\n",
    "A PDF file is not a simple stream of text like a `.txt` file. It is a set of instructions for a printer (e.g., \"draw character 'A' at coordinates x:50, y:100\").\n",
    "\n",
    "Because of this, extracting text from a PDF is often \"messy.\" You lose structural elements like columns, headers, or tables unless you use specialized OCR or layout-aware parsers. For basic RAG, we simply need to extract the raw text content so we can process it.\n",
    "\n",
    "### Mechanics\n",
    "\n",
    "We use libraries (like `pypdf`, `PyMuPDF`, or `pdfplumber`) to iterate through the binary pages of the file and attempt to reconstruct the string of text contained within.\n",
    "\n",
    "### Simpler Explanation\n",
    "\n",
    "Imagine a PDF is a painting of a letter. You can't just copy-paste the paint. You need a tool that looks at the painting and writes down the words it sees into a notepad (String).\n",
    "\n",
    "### Trade-offs\n",
    "   * **Pros:** Allows us to unlock the vast amount of knowledge stored in business documents.\n",
    "   * **Cons:** Formatting is often lost. \"Page numbers\", \"headers\", and \"footers\" get mixed in with the actual content, which can confuse the AI later if not cleaned (though for this exercise, we will stick to raw extraction).\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Add a method `load_pdf` to your `VectorStore` class (or keep it as a standalone helper function, your choice, but helper function is usually cleaner for ingestion scripts).\n",
    "\n",
    "**Specifications:**\n",
    "   1. Input: A file path string (e.g., `\"sample.pdf\"`).\n",
    "   2. Logic:\n",
    "      * Open the file in binary read mode (`rb`).\n",
    "      * Use a PDF library (standard choice is `pypdf` or `PyPDF2`) to read the file.\n",
    "      * Iterate through every page.\n",
    "      * Extract text from the page and append it to a single result string.\n",
    "   3. Output: Return the full text of the PDF as one long string.\n",
    "\n",
    "**Note:** If you don't have a specific PDF library installed, you might need to `pip install pypdf` first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb2b3a-e6d0-4d57-9b28-f0c6ba318bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pypdf\n",
    "\n",
    "class VectorStore():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor contains path to the chroma db\n",
    "        \"\"\"\n",
    "        self.client = chromadb.PersistentClient(path = r\"Data/\")\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        \"\"\"\n",
    "        Create a new collection or gets the existing collection\n",
    "        \"\"\"\n",
    "        collection = self.client.get_or_create_collection(name = \"my_knowledge_base\")\n",
    "        return collection\n",
    "\n",
    "    def load_pdf(self, file):\n",
    "        \"\"\"\n",
    "        Loads all the text of the pdf into a string. Splits each page with a \\n\\n\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        reader = pypdf.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            texts.append(text)\n",
    "        return \"\\n\\n\".join(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12009bc3-bb57-4dd1-aa58-f18636789401",
   "metadata": {},
   "source": [
    "\n",
    "## **Concept 3: Text Splitting (Recursive Strategies)**\n",
    "\n",
    "### Intuition\n",
    "\n",
    "You cannot feed a whole 50-page PDF into an LLM for two reasons:\n",
    "   1. **Token Limits:** LLMs have a maximum context window.\n",
    "   2. **Precision:** If you ask \"What is the revenue?\", you want the specific *paragraph* about revenue, not the entire annual report. Feeding the whole document dilutes the \"signal\" with too much \"noise.\"\n",
    "\n",
    "We must break the text into smaller **Chunks**.\n",
    "\n",
    "### Mechanics: Recursive Character Splitting\n",
    "\n",
    "We don't just chop the text every 1000 characters blindly. If we did, we might cut a sentence in half:\n",
    "   * *Chunk 1:* \"...the revenue was $5\"\n",
    "   * *Chunk 2:* \"million.\"\n",
    "This destroys the meaning.\n",
    "\n",
    "**Recursive Splitting** tries to keep related text together:\n",
    "   1. First, try splitting by **Paragraphs** (`\\n\\n`).\n",
    "   2. If a paragraph is still too big, split it by **Lines** (`\\n`).\n",
    "   3. If a line is too big, split by **Spaces** (` `).\n",
    "   4. Finally, force a split by characters.\n",
    "\n",
    "### The \"Overlap\"\n",
    "\n",
    "We also add an **Overlap** (e.g., 100 characters). The end of Chunk 1 is repeated as the start of Chunk 2.\n",
    "   * *Reason:* This ensures that if a concept spans across the cut, the context is preserved in at least one of the chunks.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "For this exercise, we will implement a simplified **Sliding Window Splitter** manually to understand the math of \"Overlap\" (building a full recursive splitter is complex regex work).\n",
    "\n",
    "**Specifications:**\n",
    "   1. Add a method `split_text` to your class (or as a helper).\n",
    "   2. **Inputs:** `text` (str), `chunk_size` (int, default 1000), `chunk_overlap` (int, default 200).\n",
    "   3. **Logic:**\n",
    "      * Create a loop that slices the text.\n",
    "      * Start at index `0`.\n",
    "      * Slice from `start` to `start + chunk_size`.\n",
    "      * Move the start index forward by `chunk_size - chunk_overlap`.   \n",
    "   4. **Output:** Return a list of text chunks (List[str]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea2942-6d9f-4c03-b057-d4a693a35542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pypdf\n",
    "\n",
    "class VectorStore():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor contains path to the chroma db\n",
    "        \"\"\"\n",
    "        self.client = chromadb.PersistentClient(path = r\"Data/\")\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        \"\"\"\n",
    "        Create a new collection or gets the existing collection\n",
    "        \"\"\"\n",
    "        collection = self.client.get_or_create_collection(name = \"my_knowledge_base\")\n",
    "        return collection\n",
    "\n",
    "    def load_pdf(self, file):\n",
    "        \"\"\"\n",
    "        Loads all the text of the pdf into a string. Splits each page with a \\n\\n\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        reader = pypdf.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            texts.append(text)\n",
    "        return \"\\n\\n\".join(texts)\n",
    "\n",
    "    def split_text(self, text, chunk_size = 1000, chunk_overlap = 200):\n",
    "        \"\"\"\n",
    "        Sliding Window Splitter manually to understand the math of \"Overlap\"\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            chunks.append(text[start: start + chunk_size])\n",
    "            start += chunk_size - chunk_overlap\n",
    "        return chunks\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7bf8fd-b3f2-4b6c-af18-a00bfa59c8f9",
   "metadata": {},
   "source": [
    "The `while` loop gives you precise control over the index, ensuring the overlap is calculated correctly (jumping forward by `chunk_size - overlap`).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Concept 4: Embedding Generation (The Bridge)**\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Computers cannot understand the string `\"Revenue increased\"`. They only understand numbers.\n",
    "An **Embedding Model** acts as a translator. It accepts text and outputs a fixed-length list of floating-point numbers (a vector).\n",
    "   * **Input:** \"Apple\"\n",
    "   * **Output:** `[0.12, -0.98, 0.05, ...]` (e.g., 384 dimensions)\n",
    "\n",
    "Crucially, this translation is **semantic**.\n",
    "   * The vector for \"Apple\" will be mathematically closer to \"Banana\" (both fruits) than to \"Microsoft\" (tech company).\n",
    "   * However, \"Apple\" (the company) would be closer to \"Microsoft\" based on context. High-quality models capture this nuance.\n",
    "\n",
    "### Mechanics\n",
    "\n",
    "We typically use pre-trained Transformers (like BERT or RoBERTa). We feed the text in, and instead of asking for a classification (Cat/Dog), we intercept the numbers at the **last hidden layer**. That array of numbers *is* the embedding.\n",
    "\n",
    "For this lesson, we will use ChromaDB's built-in default utility, which uses the `all-MiniLM-L6-v2` model (a very fast, lightweight model).\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Before we ingest data, I want you to \"see\" a vector to demystify it.\n",
    "   1. Import `embedding_functions` from `chromadb.utils`.\n",
    "   2. Instantiate a `DefaultEmbeddingFunction`.\n",
    "   3. Run this function on the string `\"Hello world\"` and print the **length** of the resulting vector (to see the dimensionality) and the **first 5 numbers**.\n",
    "\n",
    "*Note: This might download a small model file on the first run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf8075f-621e-4778-b1cb-07f78dfb0cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0571016 ,  0.09410139, -0.04296125,  0.0151904 ,  0.00359094],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chromadb.utils.embedding_functions import DefaultEmbeddingFunction\n",
    "\n",
    "embed = DefaultEmbeddingFunction()\n",
    "text_embed = embed(\"Hello World\")\n",
    "text_embed[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b4486-e5b2-42d7-a3d4-9f46621bde19",
   "metadata": {},
   "source": [
    "That confirms your environment is set up correctly. The default model (`all-MiniLM-L6-v2`) produces 384-dimensional vectors. This means every piece of text you ingest becomes a point in a 384-dimensional coordinate system.\n",
    "\n",
    "---\n",
    "\n",
    "## **Concept 5: Ingestion (Collections & Upsert)**\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Now we combine everything. Ingestion is the pipeline of:\n",
    "**Raw PDF  Text String  Chunks  Vectors  Storage.**\n",
    "\n",
    "### Mechanics\n",
    "\n",
    "ChromaDB's `collection.add()` method handles the heavy lifting.\n",
    "You provide:\n",
    "   1. **Documents:** The list of text chunks (strings).\n",
    "   2. **IDs:** A unique identifier for each chunk (e.g., \"pdf1_chunk0\", \"pdf1_chunk1\").\n",
    "   3. **Embeddings:** (Optional) If you don't provide them, Chroma runs the default embedding function (from Concept 4) automatically on the documents.\n",
    "   4. **Metadatas:** (Optional) Dictionaries carrying extra info (e.g., `{\"source\": \"annual_report.pdf\", \"page\": 10}`).\n",
    "\n",
    "### Simpler Explanation\n",
    "\n",
    "This is the \"Data Entry\" phase. We are taking the messy pile of paper (PDF), cutting it into index cards (Chunks), writing a summary number on the back (Vector), and filing them into the cabinet (Collection).\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Update your `VectorStore` class by adding a method `ingest_pdf`.\n",
    "\n",
    "**Specifications:**\n",
    "   1. **Input:** `pdf_path` (str).\n",
    "   2. **Workflow:**\n",
    "      * Call `load_pdf` to get the raw text.\n",
    "      * Call `split_text` to get the list of chunks.\n",
    "      * **Generate IDs:** Create a list of unique IDs matching the number of chunks (e.g., using `f\"id_{i}\"` in a loop or comprehension).\n",
    "      * **Add to DB:** Call `self.collection.add` with `documents` and `ids`.\n",
    "      * *Note:* You might need to ensure `self.collection` is defined in your `__init__` or called via `get_or_create_collection` before adding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01d85c8-193a-4c3d-bb92-518b5767ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pypdf\n",
    "import os\n",
    "\n",
    "class VectorStore():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor contains path to the chroma db\n",
    "        \"\"\"\n",
    "        self.client = chromadb.PersistentClient(path = r\"Data/\")\n",
    "        self.collection = None\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        \"\"\"\n",
    "        Create a new collection or gets the existing collection\n",
    "        \"\"\"\n",
    "        collection = self.client.get_or_create_collection(name = \"my_knowledge_base\")\n",
    "        self.collection = collection\n",
    "        return collection\n",
    "\n",
    "    def load_pdf(self, file):\n",
    "        \"\"\"\n",
    "        Loads all the text of the pdf into a string. Splits each page with a \\n\\n\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        reader = pypdf.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            texts.append(text)\n",
    "        return \"\\n\\n\".join(texts)\n",
    "\n",
    "    def split_text(self, text, chunk_size = 1000, chunk_overlap = 200):\n",
    "        \"\"\"\n",
    "        Sliding Window Splitter manually to understand the math of \"Overlap\"\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            chunks.append(text[start: start + chunk_size])\n",
    "            start += chunk_size - chunk_overlap\n",
    "        return chunks\n",
    "\n",
    "\n",
    "    def ingest_pdf(self, pdf_path):\n",
    "        \"\"\"\n",
    "        One function to run them all\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"collection\") or self.collection is None:\n",
    "            self.collection = self.get_or_create_collection()\n",
    "        \n",
    "        all_texts = self.load_pdf(pdf_path)\n",
    "        chunks = self.split_text(all_texts)\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        ids = [f\"F_{filename}_id_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "        self.collection.add(documents = chunks, ids = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfbc7f-f28e-436f-84ca-a58d93779373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "This is functional and robust. You have successfully built a pipeline that goes from Disk $\\rightarrow$ Memory $\\rightarrow$ Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9b616-a3df-4677-ba09-2887e6209239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b2722-5709-47b4-abc7-ecfd43ea5fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec00cd-f25c-40ea-b6b4-de7ed430d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd100e94-96d4-4e51-83a6-01ac1e2f2136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcee8c3-8ced-4a0b-949d-b404faa1eb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8839628-a82c-469e-a3c4-12ca08a705a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18adc1-fa4b-4f3d-81ef-0668003d9387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8786eb-16cc-46e7-9065-f44937c0b3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad1679-8eb0-4833-bf07-23fba03c20aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55852fe6-efa3-4dd4-b960-518a39be611a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810c061-6846-43da-b755-d2aaedd52b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
